{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"painting_run_Taylor_SpReg.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7dbf293e108844b4a9c53d52456cb250":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0bc0a4d9b0d4a0aa3562022ba4086d4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f4e77f14ebba4ef69197561e2727b789","IPY_MODEL_e21e239fea874b81b054568b1270da67"]}},"a0bc0a4d9b0d4a0aa3562022ba4086d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f4e77f14ebba4ef69197561e2727b789":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b49ec8b83c494ea185890bc0e1109997","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_591c84ac18994b15bd737c3ad5639c91"}},"e21e239fea874b81b054568b1270da67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0b23d7636f7b40e4a3ae60d87ff9b39e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:06&lt;00:00, 25230133.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_27b07f144051486eaeb416d51f469272"}},"b49ec8b83c494ea185890bc0e1109997":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"591c84ac18994b15bd737c3ad5639c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b23d7636f7b40e4a3ae60d87ff9b39e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"27b07f144051486eaeb416d51f469272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc4e56af240145b891762b32ef381316":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a61aaafef4ef462f8f168ff4e8386310","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4010b5ff939847c9a9d258d53a32726d","IPY_MODEL_6135969bbdcd4f378b49a8de5f78d191"]}},"a61aaafef4ef462f8f168ff4e8386310":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4010b5ff939847c9a9d258d53a32726d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2fbfaf6c56cf4922985779eb5656e44b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f8016b0fe544585a75371f7dd017e5d"}},"6135969bbdcd4f378b49a8de5f78d191":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61fbd2be83d045dfa52d2678d765d3bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [00:02&lt;00:00, 224MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3641969dde2d4db98291c4d53c6d232e"}},"2fbfaf6c56cf4922985779eb5656e44b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7f8016b0fe544585a75371f7dd017e5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61fbd2be83d045dfa52d2678d765d3bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3641969dde2d4db98291c4d53c6d232e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"NpP1lFDHP4nm"},"source":["M. Amintoosi\n","\n","# Pruning deep neural networks to make them fast and small\n","\n","https://jacobgil.github.io/deeplearning/pruning-deep-learning"]},{"cell_type":"code","metadata":{"id":"i9heXou58lAF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616740984110,"user_tz":-270,"elapsed":42037,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"38f8e310-a42b-4a79-b50c-b5f37e776ece"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i5czjq6_8lAK","executionInfo":{"status":"ok","timestamp":1616740989397,"user_tz":-270,"elapsed":1971,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}}},"source":["import os, shutil\n","from os import listdir\n","from os.path import isfile, join\n","from pathlib import Path\n","# import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, confusion_matrix\n","import time\n","from time import strftime\n","import datetime\n","import importlib"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qeiu88GAdjh0","executionInfo":{"status":"ok","timestamp":1616740995632,"user_tz":-270,"elapsed":4997,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}}},"source":["import argparse\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchsummary import summary\n","import pickle\n","from torchvision import models"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjdtb08j8lAN","executionInfo":{"status":"ok","timestamp":1616740999829,"user_tz":-270,"elapsed":1568,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}}},"source":["MAT_web_dir = '/content/drive/My Drive/onlyOnWeb/'#sparse/pytorch-pruning/'\n","datasets_dir = MAT_web_dir + 'datasets/'\n","model_web_dir = MAT_web_dir + \"sparse/HGSPR/models/\"\n","local_output_dir = '/content/drive/My Drive/codes/Sparse/pytorch-pruning/doc/output'\n","base_dir ='/content/drive/My Drive/codes/Sparse/pytorch-pruning/'\n","data_dir = '/content/data'\n","# data_dir = '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data'\n","# data_file = datasets_dir+'cats_and_dogs_small.zip'\n","# model_dir = 'C:/temp/tmp/sparse/HGSPR/'\n","Path(MAT_web_dir).mkdir(parents=True, exist_ok=True)\n","Path(local_output_dir).mkdir(parents=True, exist_ok=True)\n","Path(data_dir).mkdir(parents=True, exist_ok=True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5Yz8KtuAeJt"},"source":["# os.chdir(data_dir)\n","# !unzip -q /content/drive/My\\ Drive/codes/Sparse/pytorch-pruning/data/painting.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xK8ecCezAoXQ"},"source":["# !ls "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tg0_A5hGkaBe","executionInfo":{"status":"ok","timestamp":1616741016212,"user_tz":-270,"elapsed":1999,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}}},"source":["os.chdir(base_dir)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jp7YayEikf-M"},"source":["# %%time\n","# %run finetune_reg_ds.py --train --use-cuda --use-reg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"THmoHqALiZZZ","colab":{"base_uri":"https://localhost:8080/","height":594,"referenced_widgets":["7dbf293e108844b4a9c53d52456cb250","a0bc0a4d9b0d4a0aa3562022ba4086d4","f4e77f14ebba4ef69197561e2727b789","e21e239fea874b81b054568b1270da67","b49ec8b83c494ea185890bc0e1109997","591c84ac18994b15bd737c3ad5639c91","0b23d7636f7b40e4a3ae60d87ff9b39e","27b07f144051486eaeb416d51f469272"]},"executionInfo":{"status":"ok","timestamp":1600455151310,"user_tz":-270,"elapsed":15982,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"3085766b-3e31-4273-c450-d64130b45bfa"},"source":["%%time\n","%run finetune_reg_ds.py --prune --use-cuda"],"execution_count":null,"outputs":[{"output_type":"stream","text":["233 92.43\n","Using CUDA...\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dbf293e108844b4a9c53d52456cb250","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /content/data/cifar-10-python.tar.gz to /content/data\n","\n","Files already downloaded and verified\n","Accuracy : 0.9243\n","Number of prunning iterations to reduce 75% filters 0\n"],"name":"stdout"},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/content/drive/My Drive/codes/Sparse/pytorch-pruning/finetune_reg_ds.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdsName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_reg_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mfine_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mfine_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_test_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/codes/Sparse/pytorch-pruning/finetune_reg_ds.py\u001b[0m in \u001b[0;36mprune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mmodels_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/onlyOnWeb/sparse/pytorch-pruning/models/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# torch.save(model.state_dict(), models_dir+\"painting_model_prunned.pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"cifar10_model_taylor_prunned.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'model' referenced before assignment"]},{"output_type":"stream","text":["CPU times: user 5.67 s, sys: 1.8 s, total: 7.47 s\n","Wall time: 14.1 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rUrsCw6nklAZ","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1600454089003,"user_tz":-270,"elapsed":12391,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"94f5c46b-5c6a-440d-909d-78aad31f13a0"},"source":["import importlib\n","from models import vggTrained#alexnet, resnet, vgg\n","# importlib.reload(alexnet)\n","# importlib.reload(resnet)\n","importlib.reload(vggTrained)\n","num_classes=10\n","mdlFileName = model_web_dir+\"vgg_model_cifar10_gpu.pth\"\n","checkpoint = torch.load(mdlFileName)\n","start_epoch = checkpoint['epoch']\n","best_prec1 = checkpoint['best_prec1']\n","print(start_epoch,best_prec1)\n","\n","# import vggTrained\n","# importlib.reload(vggTrained)\n","model_gpu = vggTrained.__dict__['vgg19']()\n","model_gpu.features = torch.nn.DataParallel(model_gpu.features)\n","# model_gpu.cpu()\n","model_gpu.cuda()\n","model_gpu.load_state_dict(checkpoint['state_dict'])\n","print(model_gpu)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["233 92.43\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-be5f693cbeef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ExSvxtUOf7JF","colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"status":"ok","timestamp":1600455729670,"user_tz":-270,"elapsed":1774,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"fd783529-cf1a-41f0-d6ca-a83e80275f96"},"source":["# print(model_gpu)\n","# summary(model_gpu,(3,32,32))\n","# روش دسترسی به اجزای شبکه در \n","# pytorch_prunning is different with HGSR and vgg pretrained model in CIFAR10\n","# اگه قرار به استفاده از اون مدل از قبل آموزش دیده باشه باید خیلی از موارد اصلاح بشن\n","# گیر الان عدم همخوانی پارامترهای مدل‌های ساده‌تر با ساختار مدل اینجاس\n","# برای مدل ۱۶ مشکلی نداریم\n","# اما زمانش طولانی میشه\n","filters = 0\n","for name, module in model.named_modules():\n","    if isinstance(module, nn.Conv2d):\n","        print(module)\n","        filters = filters + module.out_channels\n","filters"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["5504"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"--bFq_vklhV7","colab":{"base_uri":"https://localhost:8080/","height":973,"referenced_widgets":["cc4e56af240145b891762b32ef381316","a61aaafef4ef462f8f168ff4e8386310","4010b5ff939847c9a9d258d53a32726d","6135969bbdcd4f378b49a8de5f78d191","2fbfaf6c56cf4922985779eb5656e44b","7f8016b0fe544585a75371f7dd017e5d","61fbd2be83d045dfa52d2678d765d3bb","3641969dde2d4db98291c4d53c6d232e"]},"executionInfo":{"status":"ok","timestamp":1616741168932,"user_tz":-270,"elapsed":100984,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"7c9664a0-f135-4ce1-d9bc-d89b5cb9b6aa"},"source":["%%time\n","%run finetune_SpReg.py --train --use-cuda --train_path '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data/painting/train' --test_path '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data/painting/test'"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc4e56af240145b891762b32ef381316","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Using CUDA...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch:  0 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  1 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  2 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  3 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  4 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  5 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  6 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  7 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  8 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  9 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  10 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  11 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  12 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  13 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Epoch:  14 / 15\n","torch.Size([32, 3, 224, 224]) torch.Size([32])\n","Accuracy : 0.53125\n","Finished fine tuning.\n","CPU times: user 9.26 s, sys: 8.66 s, total: 17.9 s\n","Wall time: 1min 39s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MAhrCTM_q_w7","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600350678272,"user_tz":-270,"elapsed":1333055,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"440564d3-4045-4eef-dc7d-a7e5888be5e0"},"source":["%%time\n","%run finetune_SpReg.py --prune --use-cuda --train_path '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data/painting/train' --test_path '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data/painting/test'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using CUDA...\n","Accuracy : 0.90625\n","Number of prunning iterations to reduce 75% filters 6\n","Iter:  0 / 6\n","Ranking filters.. \n","Layers that will be prunned {28: 123, 12: 15, 10: 19, 26: 73, 21: 59, 24: 77, 17: 76, 19: 42, 0: 5, 2: 3, 5: 3, 14: 15, 7: 2}\n","Prunning filters.. \n","Filters prunned 12.121212121212125%\n","Accuracy : 0.921875\n","Fine tuning to recover from prunning iteration.\n","Epoch:  0 / 10\n","Accuracy : 0.984375\n","Epoch:  1 / 10\n","Accuracy : 0.921875\n","Epoch:  2 / 10\n","Accuracy : 0.96875\n","Epoch:  3 / 10\n","Accuracy : 0.96875\n","Epoch:  4 / 10\n","Accuracy : 0.96875\n","Epoch:  5 / 10\n","Accuracy : 0.96875\n","Epoch:  6 / 10\n","Accuracy : 1.0\n","Epoch:  7 / 10\n","Accuracy : 1.0\n","Epoch:  8 / 10\n","Accuracy : 1.0\n","Epoch:  9 / 10\n","Accuracy : 1.0\n","Finished fine tuning.\n","Iter:  1 / 6\n","Ranking filters.. \n","Layers that will be prunned {28: 184, 24: 69, 17: 37, 12: 13, 21: 43, 19: 48, 26: 86, 14: 8, 10: 11, 5: 4, 7: 5, 0: 3, 2: 1}\n","Prunning filters.. \n","Filters prunned 24.24242424242425%\n","Accuracy : 1.0\n","Fine tuning to recover from prunning iteration.\n","Epoch:  0 / 10\n","Accuracy : 0.984375\n","Epoch:  1 / 10\n","Accuracy : 0.984375\n","Epoch:  2 / 10\n","Accuracy : 0.96875\n","Epoch:  3 / 10\n","Accuracy : 1.0\n","Epoch:  4 / 10\n","Accuracy : 1.0\n","Epoch:  5 / 10\n","Accuracy : 0.96875\n","Epoch:  6 / 10\n","Accuracy : 0.984375\n","Epoch:  7 / 10\n","Accuracy : 0.953125\n","Epoch:  8 / 10\n","Accuracy : 0.96875\n","Epoch:  9 / 10\n","Accuracy : 0.953125\n","Finished fine tuning.\n","Iter:  2 / 6\n","Ranking filters.. \n","Layers that will be prunned {24: 89, 14: 21, 19: 56, 26: 102, 21: 73, 12: 17, 28: 64, 17: 58, 5: 7, 10: 19, 7: 3, 2: 3}\n","Prunning filters.. \n","Filters prunned 36.36363636363637%\n","Accuracy : 0.984375\n","Fine tuning to recover from prunning iteration.\n","Epoch:  0 / 10\n","Accuracy : 1.0\n","Epoch:  1 / 10\n","Accuracy : 0.984375\n","Epoch:  2 / 10\n","Accuracy : 1.0\n","Epoch:  3 / 10\n","Accuracy : 0.984375\n","Epoch:  4 / 10\n","Accuracy : 1.0\n","Epoch:  5 / 10\n","Accuracy : 1.0\n","Epoch:  6 / 10\n","Accuracy : 1.0\n","Epoch:  7 / 10\n","Accuracy : 0.90625\n","Epoch:  8 / 10\n","Accuracy : 0.984375\n","Epoch:  9 / 10\n","Accuracy : 1.0\n","Finished fine tuning.\n","Iter:  3 / 6\n","Ranking filters.. \n","Layers that will be prunned {26: 85, 7: 20, 19: 53, 17: 62, 12: 29, 28: 57, 21: 65, 10: 33, 5: 14, 24: 58, 2: 5, 14: 27, 0: 4}\n","Prunning filters.. \n","Filters prunned 48.484848484848484%\n","Accuracy : 1.0\n","Fine tuning to recover from prunning iteration.\n","Epoch:  0 / 10\n","Accuracy : 0.953125\n","Epoch:  1 / 10\n","Accuracy : 0.921875\n","Epoch:  2 / 10\n","Accuracy : 0.984375\n","Epoch:  3 / 10\n","Accuracy : 1.0\n","Epoch:  4 / 10\n","Accuracy : 0.96875\n","Epoch:  5 / 10\n","Accuracy : 0.96875\n","Epoch:  6 / 10\n","Accuracy : 0.96875\n","Epoch:  7 / 10\n","Accuracy : 0.9375\n","Epoch:  8 / 10\n","Accuracy : 0.984375\n","Epoch:  9 / 10\n","Accuracy : 0.96875\n","Finished fine tuning.\n","Iter:  4 / 6\n","Ranking filters.. \n","Layers that will be prunned {28: 29, 26: 68, 21: 89, 19: 70, 17: 63, 24: 65, 14: 38, 10: 34, 2: 1, 12: 25, 5: 15, 7: 14, 0: 1}\n","Prunning filters.. \n","Filters prunned 60.60606060606061%\n","Accuracy : 1.0\n","Fine tuning to recover from prunning iteration.\n","Epoch:  0 / 10\n","Accuracy : 0.96875\n","Epoch:  1 / 10\n","Accuracy : 0.9375\n","Epoch:  2 / 10\n","Accuracy : 0.96875\n","Epoch:  3 / 10\n","Accuracy : 0.984375\n","Epoch:  4 / 10\n","Accuracy : 0.96875\n","Epoch:  5 / 10\n","Accuracy : 1.0\n","Epoch:  6 / 10\n","Accuracy : 0.984375\n","Epoch:  7 / 10\n","Accuracy : 0.984375\n","Epoch:  8 / 10\n","Accuracy : 0.96875\n","Epoch:  9 / 10\n","Accuracy : 0.9375\n","Finished fine tuning.\n","Iter:  5 / 6\n","Ranking filters.. \n","Layers that will be prunned {5: 14, 19: 88, 10: 35, 26: 36, 17: 80, 21: 78, 24: 50, 7: 17, 12: 36, 0: 15, 14: 38, 2: 13, 28: 12}\n","Prunning filters.. \n","Filters prunned 72.72727272727272%\n","Accuracy : 0.921875\n","Fine tuning to recover from prunning iteration.\n","Epoch:  0 / 10\n","Accuracy : 0.875\n","Epoch:  1 / 10\n","Accuracy : 1.0\n","Epoch:  2 / 10\n","Accuracy : 0.953125\n","Epoch:  3 / 10\n","Accuracy : 0.96875\n","Epoch:  4 / 10\n","Accuracy : 0.984375\n","Epoch:  5 / 10\n","Accuracy : 0.9375\n","Epoch:  6 / 10\n","Accuracy : 1.0\n","Epoch:  7 / 10\n","Accuracy : 0.953125\n","Epoch:  8 / 10\n","Accuracy : 0.984375\n","Epoch:  9 / 10\n","Accuracy : 0.9375\n","Finished fine tuning.\n","CPU times: user 13min 43s, sys: 6min 10s, total: 19min 53s\n","Wall time: 22min 11s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YpPIn2ECMLdT"},"source":["%run finetune_SpReg.py --test --train_path '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data/painting/train' --test_path '/content/drive/My Drive/codes/Sparse/pytorch-pruning/data/painting/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjVbaVPqC8Su","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1600365441986,"user_tz":-270,"elapsed":2306,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"de5979e4-43b0-4a4b-c9ab-b7a58ee0668c"},"source":["import importlib\n","# models_dir = '/content/drive/My Drive/onlyOnWeb/sparse/pytorch-pruning/models/'\n","# model =  models.vgg16(pretrained=True)\n","# model = torch.load(models_dir+\"painting_model.pt\", map_location=lambda storage, loc: storage)\n","from finetune_reg_ds import ModifiedVGG16Model\n","# import finetune_reg_ds\n","from torchsummary import summary\n","# importlib.reload(finetune_reg_ds)#.ModifiedVGG16Model)\n","model = ModifiedVGG16Model()\n","print(model)\n","net = model.to('cuda')\n","summary(net, (3, 224, 224))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ModifiedVGG16Model(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=25088, out_features=512, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=512, out_features=512, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-e37d5bb7aa5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/codes/Sparse/pytorch-pruning/finetune_reg_ds.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"]}]},{"cell_type":"code","metadata":{"id":"fdKYrGeMDIAR"},"source":["# models_dir = '/content/drive/My Drive/onlyOnWeb/sparse/pytorch-pruning/models/'\n","# from torchsummary import summary\n","# model = torch.load(models_dir+\"painting_model_prunned.pt\")#,strict=False)\n","# # print(model)\n","# net = model.to('cuda')\n","# summary(net, (3, 224, 224))\n","# # print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BEdKGq2nDko_"},"source":["# %run finetune_SpReg.py --test --train_path data/painting/train --test_path data/painting/test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19N4_r8ge00m"},"source":["# %run finetune_SpReg.py --test --train_path data/painting/train --test_path data/painting/test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IuF9HK1Me00v"},"source":["# %run finetune_SpReg.py --test --train_path data/painting/train --test_path data/painting/test"],"execution_count":null,"outputs":[]}]}